# Spatial_VLM_Survey

## Benchmark Evaluation of Spatial Vision-Language Models
Facilitating the evaluation of published spatial related benchmarks, we summarize the dataset used in the evaluation section.

The related code stores in the [here](./code/evaluation/)



We recollect the published spatial related datasets for evaluation. The following table summarizes the key datasets used for benchmarking spatial vision-language models:

| Dataset Name | Description  | Link |
|--------------|--------------|------|
| EgoOrientBench | -- |  |
| GeoMeter | -- |  |
| SEED-Bench(Spatial Relation section)| -- |  |
| MM-Vet(Spatial awareness (Spat))| -- |  |
| CV-Bench| -- | [Link](https://huggingface.co/datasets/nyu-visionx/CV-Bench) |
| What's Up| -- |  |
| VSP | -- |  |
| srbench | -- | [Link](https://huggingface.co/datasets/stogian/srbench) |
| MINDCUBE| -- | [Link](https://huggingface.co/datasets/MLL-Lab/MindCube) |
| ViewSpatial-Bench | -- | [Link](https://huggingface.co/datasets/lidingm/ViewSpatial-Bench) |
| SPHERE| -- | [Link](https://huggingface.co/datasets/wei2912/SPHERE-VLM) |
| OmniSpatial| -- | [Link](https://huggingface.co/datasets/qizekun/OmniSpatial) |
